{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Custom Image Processing Techniques\n",
    "   Objective: Implement custom techniques for processing images.\n",
    "\n",
    "Image Resizing: Resize images to a consistent dimension (e.g., 32x32 for CIFAR-10 images) to ensure uniform input for models.\n",
    "Color Histogram Normalization: Normalize the RGB histograms of the images to improve model performance under varying lighting conditions.\n",
    "Edge Detection (e.g., Sobel Filter): Apply edge detection to focus on the object's boundaries, which can improve classifier accuracy by reducing background noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Example: Sobel Edge Detection\n",
    "def sobel_edge_detection(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel_edges = np.hypot(sobel_x, sobel_y)\n",
    "    sobel_edges = np.uint8(np.clip(sobel_edges, 0, 255))\n",
    "    return sobel_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: Use custom image filters and adjustments (e.g., brightness/contrast adjustments) for preprocessing images and testing their effect on model accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Traditional Machine Learning Classifiers\n",
    "   Objective: Implement at least one traditional ML classifier, such as SVM, KNN, or Logistic Regression.\n",
    "\n",
    "Data Flattening: Flatten CIFAR-10 images (32x32x3) into one-dimensional vectors for use in traditional classifiers.\n",
    "Model Selection: Train and test using classifiers like SVM or KNN for a baseline comparison with CNNs.\n",
    "python\n",
    "Copy code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten images for traditional classifiers\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=100)\n",
    "x_train_pca = pca.fit_transform(x_train_flat)\n",
    "x_test_pca = pca.transform(x_test_flat)\n",
    "\n",
    "# SVM classifier\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(x_train_pca, y_train.ravel())\n",
    "\n",
    "# Evaluate SVM model\n",
    "y_pred = svm_model.predict(x_test_pca)\n",
    "print(\"SVM Model Accuracy:\", accuracy_score(y_test.ravel(), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: This baseline model will serve as a comparison to the performance of CNNs and help validate the overall system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convolutional Neural Networks (CNNs)\n",
    "   Objective: Implement CNNs for better feature extraction and image classification.\n",
    "\n",
    "Layer Architecture: Use convolutional layers, pooling, and dropout layers to improve performance.\n",
    "Model Optimization: Tuning CNN architectures, adding more layers, or using pre-trained models (like ResNet) can improve results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "cnn_model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "cnn_model.fit(\n",
    "    x_train, y_train_onehot, epochs=20, validation_data=(x_test, y_test_onehot)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: This will be your main model for performance and comparison. CNNs are essential for extracting hierarchical features from images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data Augmentation and Preprocessing Pipeline\n",
    "   Objective: Apply data augmentation to artificially increase the size of your training dataset and improve model generalization.\n",
    "\n",
    "Techniques: Use transformations like rotation, flipping, zooming, and shifts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Train with augmented data\n",
    "cnn_model.fit(\n",
    "    datagen.flow(x_train, y_train_onehot, batch_size=64),\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test_onehot),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: Data augmentation helps prevent overfitting, especially with limited training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Performance Optimization Techniques\n",
    "   Objective: Use techniques to speed up training and improve model efficiency.\n",
    "\n",
    "Optimization: Implement early stopping, learning rate schedules, and model checkpoints.\n",
    "Batch Normalization and Regularization: Improve training speed and prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "cnn_model.fit(\n",
    "    x_train,\n",
    "    y_train_onehot,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test_onehot),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: This will ensure that the model doesnâ€™t overfit and helps to stabilize the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Proper Validation and Testing Methodologies\n",
    "   Objective: Split the data into training, validation, and test sets. Perform k-fold cross-validation if necessary.\n",
    "\n",
    "Split Data: Split CIFAR-10 into training, validation, and test sets to ensure proper evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train_onehot, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: This step ensures that you evaluate the model's performance objectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Visualization of Results and Model Performance\n",
    "   Objective: Visualize the performance using charts, confusion matrices, and accuracy curves.\n",
    "\n",
    "Confusion Matrix: Helps to evaluate the classification results.\n",
    "Accuracy vs. Epoch Plot: To show how well the model is learning over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict and plot confusion matrix\n",
    "y_pred = np.argmax(cnn_model.predict(x_test), axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_test_onehot, axis=1), y_pred)\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy vs epochs\n",
    "plt.plot(cnn_model.history.history[\"accuracy\"], label=\"Accuracy\")\n",
    "plt.plot(cnn_model.history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation: These plots will help demonstrate the model's effectiveness and validate the testing methodologies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Submit the Report\n",
    "   Objective: Prepare your project report with:\n",
    "   A detailed explanation of the model architecture, data preprocessing, and evaluation.\n",
    "   Visualizations of training/validation accuracy, confusion matrices, and any custom techniques used.\n",
    "   A conclusion summarizing the results and challenges faced.\n",
    "   Conclusion:\n",
    "   By following these steps, you will meet all the technical requirements, including implementing three required techniques (custom image processing, ML classifiers, CNNs), using a real-world dataset (CIFAR-10), and ensuring proper validation, performance optimization, and visualization of results.\n",
    "\n",
    "Let me know if you need further assistance with any of the steps or implementation!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
